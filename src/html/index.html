<!doctype html>
<html lang="en">
  <head>
    {{> partials/head title="ACCDA"}}
  </head>
  <body>

    <!-- MODALS -->
    {{> partials/modals}}

    <!-- NAVBAR -->
    {{> partials/navbar classList="navbar-light bg-white fixed-top" container="container" button="primary"}}

    <!-- Introduction -->
    <section class="pt-4 pt-md-11">
      <div class="container">
        <div class="row align-items-center">
          <div class="col-12 col-md-5 col-lg-6 order-md-2">

            <!-- Image -->
            <!-- <img src="assets/img/overview.png" class="img-fluid mw-md-150 mw-lg-130 mb-6 mb-md-0" alt="..." data-aos="fade-up" data-aos-delay="100"> -->

            <!-- Video -->
            <div class="ratio ratio-16x9">
              <video class="rounded-lg bg-light shadow-lg mw-md-200 mw-lg-150 mb-6 mb-md-0" src="assets/video/illustration-video.mp4" autoplay loop muted>
                Sorry, your browser doesn't support embedded videos,
                but don't worry, you can <a href="assets/video/illustration-video.mp4">download it</a>
                and watch it with your favorite video player!
              </video>
            </div>

          </div>
          <div class="col-12 col-md-7 col-lg-6 order-md-1" data-aos="fade-up">

            <!-- Heading -->
            <h1 class="display-3 text-center text-md-start">
              <span class="text-primary">A</span>ctive <span class="text-primary">C</span>ontinous <span class="text-primary">C</span>ontinual 
              <span class="text-primary">D</span>omain <span class="text-primary">A</span>daptation
            </h1>

            <!-- Text -->
            <p class="lead text-center text-md-start text-muted mb-6 mb-lg-8">
              Adapting neural networks to complex, changing visual conditions, with minimal supervision. 
            </p>

            <!-- Buttons -->
            <div class="text-center text-md-start">
              <a href="assets/img/project-report-draft.pdf" class="btn btn-primary shadow lift me-1">
                Project Report <i class="fe fe-arrow-right d-none d-md-inline ms-3"></i>
              </a>
              <a href="https://github.com/maoli131/accda/tree/maoli" class="btn btn-primary-soft lift">
                Open-source Code
              </a>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- Highlights -->
    <section class="py-8 py-md-11 border-bottom">
      <div class="container">
        <div class="row">
          <div class="col-12 col-md-4" data-aos="fade-up">

            <!-- Icon -->
            <div class="icon text-primary mb-3">
              {{> layout/layout-arrange}}
            </div>

            <!-- Heading -->
            <h3>
              Semantic Segmentation
            </h3>

            <!-- Text -->
            <p class="text-muted mb-6 mb-md-0">
              Our project builds upon exisitng state-of-the-art models on semantic segmentation (pixel-labeling), a critical task for autonomous driving. 
            </p>

          </div>
          <div class="col-12 col-md-4" data-aos="fade-up" data-aos-delay="50">

            <!-- Icon -->
            <div class="icon text-primary mb-3">
              {{> general/settings-1}}
            </div>

            <!-- Heading -->
            <h3>
              Domain Adaptation
            </h3>

            <!-- Text -->
            <p class="text-muted mb-6 mb-md-0">
              Our project generalizes neural networks trained on well-labeled source domains, to unlabeled, continously changing target domains. 
            </p>

          </div>
          <div class="col-12 col-md-4" data-aos="fade-up" data-aos-delay="100">

            <!-- Icon -->
            <div class="icon text-primary mb-3">
              {{> code/code}}
            </div>

            <!-- Heading -->
            <h3>
              Active and Continous Continual
            </h3>

            <!-- Text -->
            <p class="text-muted mb-0">
              Our algorithms help neural networks identify the most informative unseen target samples and adapts to new conditions in real-time. 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-dark">
        {{> curves/curve-1}}
      </div>
    </div>

    <!-- Problem -->
    <section class="bg-dark pt-10 pt-md-12" id="problem">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center text-white">

            <!-- Badge -->
            <span class="badge rounded-pill bg-success mb-3">
              <span class="h6 text-uppercase">Problem Setting</span>
            </span>

            <!-- Heading -->
            <h2>
              Existing state-of-the-art neural networks <span class="text-primary">fail to generalize well</span> to unseen domains.
            </h2>

            <!-- Text -->
            <p class="fs-lg text-muted mb-7 mb-md-9">
              Neural networks can achieve state-of-the-art performance on computer vision tasks with ample training data.
              However, in real-world scenarios, labeled data for training is often limited and expensive to obtain.
              The environments in which models are deployed can evolve in unexpected ways. 
            </p>

          </div>
        </div> <!-- / .row -->
        <div class="row">
          <div class="col-12">

            <!-- Card -->
            <div class="card card-row shadow-light-lg mb-6">
              <div class="row gx-0">
                <div class="col-12 col-md-6">

                  <!-- Slider -->
                  <div class="card-img-slider" data-flickity='{"fade": true, "imagesLoaded": true, "pageDots": false, "prevNextButtons": false, "asNavFor": "#blogSlider", "draggable": false}'>
                    <a class="card-img-start w-100 bg-cover" style="background-image: url(assets/img/gta5.png);" href="#!">

                      <!-- Image (placeholder) -->
                      <img src="assets/img/gta5.png" alt="..." class="img-fluid d-md-none invisible">

                    </a>
                    <a class="card-img-start w-100 bg-cover" style="background-image: url(assets/img/viper.png);" href="#!">

                      <!-- Image (placeholder) -->
                      <img src="assets/img/viper.png" alt="..." class="img-fluid d-md-none invisible">

                    </a>
                  </div>

                  <!-- Shape -->
                  <div class="shape shape-end shape-fluid-y text-white d-none d-md-block">
                    {{> curves/curve-4}}
                  </div>

                </div>
                <div class="col-12 col-md-6 position-md-static">

                  <!-- Slider -->
                  <div class="position-md-static" data-flickity='{"wrapAround": true, "pageDots": false, "adaptiveHeight": true}' id="blogSlider">
                    <div class="w-100">

                      <!-- Body -->
                      <div class="card-body">
                        <blockquote class="blockquote text-center mb-0">

                          <!-- Footer -->
                          <footer class="blockquote-footer">
                            <span class="h5 text-uppercase">Source Domain</span>
                          </footer>

                          <!-- Text -->
                          <p class="mb-5 mb-md-7">
                            The source domains are synthesized datatsets for city and street views: <a href="https://download.visinf.tu-darmstadt.de/data/from_games/">GTA5</a> and <a href="https://synthia-dataset.net/">SYNTHIA</a>. 
                            They contain photo-realistic frames generated from virtual cities in games and have pixel-level labels for 19 and 13 classes (e.g., car, road, wall, person), respectively. 
                          </p>

                        </blockquote>
                      </div>

                    </div>
                    <div class="w-100">

                      <!-- Body -->
                      <div class="card-body">
                        <blockquote class="blockquote text-center mb-0">

                          <!-- Footer -->
                          <footer class="blockquote-footer">
                            <span class="h5 text-uppercase">Target Domain</span>
                          </footer>

                          <!-- Text -->
                          <p class="mb-5 mb-md-7">
                            The target domains are urban street view datasets containing real-world images and continously changing visual features: <a href="https://www.cityscapes-dataset.com/">CITYPSCAPES</a> 
                            and <a href="https://playing-for-benchmarks.org/">VIPER</a>. To perform semantic segmentation on these targets, networks need to adapt to these more realistic, and continously changing conditions.
                          </p>

                        </blockquote>
                      </div>

                    </div>
                  </div>

                </div>
              </div> <!-- / .row -->
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-top shape-fluid-x shape-flip-x text-dark">
        {{> angles/angle-top}}
      </div>
    </div>

    <!-- Method -->
    <section class="pt-8 pt-md-11" id="method">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Badge -->
            <span class="badge rounded-pill bg-success mb-3">
              <span class="h6 text-uppercase">Method</span>
            </span>

            <!-- Heading -->
            <h1 class="fw-bold">
              ACCDA <span class="text-primary">actively</span> select samples for learning and adapts to targets <span class="text-primary">continously</span>.
            </h1>

            <!-- Text -->
            <p class="fs-lg text-muted mb-7">
              Our project has two sub-routines. First, we design the active sample selection strategies that yield the most informative, diverse and representative data points from the unseen target. 
              Second, we research on the continous adaptation approaches that best accumulate past knowledge. 
              We then combine our finding into the novel method, ACCDA, which actively selects samples and learns on the fly. 
            </p>

          </div>
        </div> <!-- / .row -->
        <div class="row">
          <div class="col-12" data-aos="fade-up" data-aos-delay="200">
              <!-- Image -->
              <img class="position-relative img-fluid rounded-start shadow-lg" src="assets/img/method.png" alt="..." />
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- STEPS -->
    <section class="pt-8 pb-9 pt-md-11 pb-md-13">
      <div class="container">
        <div class="row">
          <div class="col-12 col-md-4">
            <div class="row">
              <div class="col-auto col-md-12">

                <!-- Step -->
                <div class="row gx-0 align-items-center mb-md-5">
                  <div class="col-auto">

                    <a href="#!" class="btn btn-sm btn-rounded-circle btn-gray-400 disabled opacity-1">
                      <span>1</span>
                    </a>

                  </div>
                  <div class="col">

                    <hr class="d-none d-md-block me-n7">

                  </div>
                </div> <!-- / .row -->

              </div>
              <div class="col col-md-12 ms-n5 ms-md-0">

                <!-- Heading -->
                <h3>
                  Adversarially learn.
                </h3>

                <!-- Text -->
                <p class="text-muted mb-6 mb-md-0">
                  ACCDA performs adversarial learning on the source samples for semantic segmentation, by minimizing cross-entropy loss. The backbone model is VGG16-Deeplab-v3.  
                </p>

              </div>
            </div> <!-- / .row -->
          </div>
          <div class="col-12 col-md-4">
            <div class="row">
              <div class="col-auto col-md-12">

                <!-- Step -->
                <div class="row gx-0 align-items-center mb-md-5">
                  <div class="col-auto">

                    <a href="#!" class="btn btn-sm btn-rounded-circle btn-gray-400 disabled opacity-1">
                      <span>2</span>
                    </a>

                  </div>
                  <div class="col">

                    <hr class="d-none d-md-block me-n7">

                  </div>
                </div> <!-- / .row -->

              </div>
              <div class="col col-md-12 ms-n5 ms-md-0">

                <!-- Heading -->
                <h3>
                  Actively select.
                </h3>

                <!-- Text -->
                <p class="text-muted mb-6 mb-md-0">
                  ACCDA then uses our novel entropy-weighted multi-anchor stragety to select a few number of informative and diverse unseen samples from target to acquire label and learn to adapt. 
                </p>

              </div>
            </div> <!-- / .row -->
          </div>
          <div class="col-12 col-md-4">
            <div class="row">
              <div class="col-auto col-md-12">

                <!-- Step -->
                <div class="row gx-0 align-items-center mb-md-5">
                  <div class="col-auto">

                    <a href="#!" class="btn btn-sm btn-rounded-circle btn-gray-400 disabled opacity-1">
                      <span>3</span>
                    </a>

                  </div>
                </div> <!-- / .row -->

              </div>
              <div class="col col-md-12 ms-n5 ms-md-0">

                <!-- Heading -->
                <h3>
                  Continously adapt.
                </h3>

                <!-- Text -->
                <p class="text-muted mb-0">
                  ACCDA adapts to continously shifting target frames with our designed replay buffer, 
                  which remembers previously-seen domain information.  
                </p>

              </div>
            </div> <!-- / .row -->
          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- SHAPE -->
    <div class="position-relative">
      <div class="shape shape-bottom shape-fluid-x text-dark">
        {{> curves/curve-2}}
      </div>
    </div>

    <!-- Active DA -->
    <section class="pt-8 pt-md-11 bg-dark">
      <div class="container">
        <div class="row align-items-center justify-content-between">
          <div class="col-12 col-md-6 col-lg-5">

            <!-- Heading -->
            <h2 class="display-3 fw-bold text-white mb-6 mb-md-8">
              Active sample selection
            </h2>

            <!-- Text -->
            <p class="text-muted lead mb-6">
              <span class="text-white fw-bold">Multi-anchor</span>. Our algorithm groups the source features into clusters and treat their centroids as anchors. It then computes the distance between target samples to the source anchors. 
            </p>

            <!-- Text -->
            <p class="text-muted lead mb-7 mb-md-0">
              <span class="text-white fw-bold">Entropy.</span> The anchor distance is then weighted by entropy to better capture the samples' informativeness. Target samples that are closest to source anchors and have high entropy are then selected. 
            </p>

          </div>
          <div class="col-12 col-md-6">

            <!-- Media -->
            <div class="position-relative vw-md-50 pt-7 ps-7 ps-md-9 overflow-hidden" style="max-width: 800px;">

              <!-- Background -->
              <div class="position-absolute top-0 end-0 bottom-0 start-0 bg-gradient-multicolor rounded-4"></div>

              <!-- Image -->
              <img class="position-relative w-100 w-md-100" src="assets/img/MADA.png" alt="...">

            </div>

          </div>
        </div> <!-- / .row -->
      </div>
    </section>

    <!-- Continous DA -->
    <section class="pt-8 pt-md-11 bg-dark">
      <div class="container">
        <div class="row align-items-center justify-content-between">
          <div class="col-12 col-md-6 col-lg-5 order-md-1">

            <!-- Heading -->
            <h2 class="display-4 fw-bold text-white mb-6 mb-md-8">
              Continous continual adaptation.
            </h2>

            <!-- Text -->
            <p class="text-muted lead mb-6">
              <span class="text-white fw-bold">Sequential adaptation.</span> We explored adaptation schemas that sequentially adapt a segmentation model to multiple gradually changing target frames. At each iteration, the
              current segmentation model will be adapted to the next target frame. 
            </p>

            <!-- Text -->
            <p class="text-muted lead mb-7 mb-md-0">
              <span class="text-white fw-bold">Replay buffer.</span> We designed a novel replay buffer that accumulates previously-seen knowledge and improve network performance in continously shifting visual frames. 
            </p>

          </div>
          <div class="col-12 col-md-6 col-lg-6 order-md-0">

            <!-- Positioner -->
            <div class="position-relative">

              <!-- Media -->
              <div class="position-relative vw-md-50 p-7 p-md-9 ps-0 overflow-hidden float-end" style="max-width: 800px;">

                <!-- Background -->
                <div class="position-absolute top-0 end-0 bottom-0 start-0 bg-gradient-multicolor rounded-4"></div>

                <!-- Image -->
                <img class="position-relative w-100 w-md-120 float-end" src="assets/img/CDA.jpeg" alt="...">

              </div>

              <!-- Icon -->
              <img class="img-fluid position-absolute top-0 end-0 mt-n5 me-n5" src="assets/img/icons/figma-dark-circle.png" alt="...">

            </div>

          </div>
        </div> <!-- / .row -->
      </div>
    </section>

    <!-- IMAGE -->
    <section class="py-14 py-lg-16 jarallax" data-jarallax data-speed=".8" style="background-image: url(assets/img/background.png);">

      <!-- Shape -->
      <div class="shape shape-top shape-fluid-x text-dark">
        {{> angles/angle-top}}
      </div>

      <!-- Shape -->
      <div class="shape shape-bottom shape-fluid-x text-white">
        {{> angles/angle-bottom}}
      </div>

    </section>

    <!-- Result -->
    <section class="pt-8 pt-md-11" id="results">
      <div class="container">
        <div class="row justify-content-center">
          <div class="col-12 col-md-10 col-lg-8 text-center">

            <!-- Badge -->
            <span class="badge rounded-pill bg-success mb-3">
              <span class="h6 text-uppercase">Results</span>
            </span>

            <!-- Heading -->
            <h1 class="fw-bold">
              ACCDA <span class="text-primary">better generalizes</span> backbone models. 
            </h1>

            <!-- Text -->
            <p class="fs-lg text-muted mb-7">
              The baseline <a href="https://github.com/wasidennis/AdaptSegNet">AdaptSegNet</a> model and our customized continous contiual segmentation model only achieve around 25% mIoU on target domain without adaptation. 
              After adaptation with our designed replay buffer, we boosts the target domain performance to around 41% mIoU. Then by integrating our novel entropy-weighted
              mutli-anchor active learning strategy, we pushes the performance further to be above 58% mIoU. 
            </p>

          </div>
        </div> <!-- / .row -->
        <div class="row">
          <iframe src="2d-plot.html" width="750" height="750"></iframe>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- Result STATS -->
    <section class="pt-8 pt-md-11">
      <div class="container">
        <div class="row">
          <div class="col-12">

            <!-- Card -->
            <div class="card-group card-border card-border-lg border-primary shadow-light-lg">
              <div class="card">
                <div class="card-body">

                  <!-- Heading -->
                  <h2 class="fw-bold text-center mb-0">
                    <span data-countup='{"startVal": 0}' data-to="25" data-aos data-aos-id="countup:in"></span>% mIoU
                  </h2>

                  <!-- Text -->
                  <p class="text-center text-muted mb-0">
                    Baseline (w/o adaptation)
                  </p>

                </div>
              </div>
              <div class="card border-start-md">
                <div class="card-body">

                  <!-- Heading -->
                  <h2 class="fw-bold text-center mb-0">
                    <span data-countup='{"startVal": 0}' data-to="30" data-aos data-aos-id="countup:in"></span>% mIoU
                  </h2>

                  <!-- Text -->
                  <p class="text-center text-muted mb-0">
                    Continous DA (w/o adaptation)
                  </p>

                </div>
              </div>
              <div class="card border-start-md">
                <div class="card-body">

                  <!-- Heading -->
                  <h2 class="fw-bold text-center mb-0">
                    <span data-countup='{"startVal": "0"}' data-to="41" data-aos data-aos-id="countup:in"></span>% mIoU
                  </h2>

                  <!-- Text -->
                  <p class="text-center text-muted mb-0">
                    Continous DA (w/ adaptation + replay)
                  </p>

                </div>
              </div>
              <div class="card border-start-md">
                <div class="card-body">

                  <!-- Heading -->
                  <h2 class="fw-bold text-center mb-0">
                    <span data-countup='{"startVal": "0"}' data-to="58" data-aos data-aos-id="countup:in"></span>% mIoU
                  </h2>

                  <!-- Text -->
                  <p class="text-center text-muted mb-0">
                    ACCDA (replay buffer + entropy multi-anchor)
                  </p>

                </div>
              </div>
            </div>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- Result 3D -->
    <section class="pt-6 pt-md-8">
      <div class="container">
        <div class="row align-items-center justify-content-center">
          <div class="col-10 col-sm-8 col-md-6 order-md-2">

            <iframe src="3d-plot.html" width="750" height="750"></iframe>

          </div>
          <div class="col-12 col-md-6 col-lg-5" data-aos="fade-right">

            <!-- Heading -->
            <h1 class="fw-bold">
              ACCDA <span class="text-primary">consistently improves</span> on unseen target. 
            </h1>

            <!-- Text -->
            <p class="fs-lg text-muted mb-6">
              The backbone network is able to achieve better and better performance on target domain, by utilizing active learning and continual, continous adaptation. 
            </p>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- CTA -->
    <section class="pt-6 pt-md-8">
      <div class="container pb-6 pb-md-8 border-bottom">
        <div class="row align-items-center">
          <div class="col-12 col-md">

            <!-- Heading -->
            <h3 class="fw-bold mb-1">
              Learn more from our paper and codebase
            </h3>

            <!-- Text -->
            <p class="fs-lg text-muted mb-6 mb-md-0">
              This project is summerized in capstone report and open-sourced on Github.
            </p>

          </div>
          <div class="col-12 col-md-auto">

            <!-- Button -->
            <a href="https://docs.google.com/document/d/1yM1k_Xyt_CMXTZ3R_mRyEuzC8Ta4CW0ME_-F4E0ADUU/edit?usp=sharing" class="btn btn-primary-soft me-1 lift">
              API
            </a>

            <a href="https://github.com/maoli131/accda/tree/maoli" class="btn btn-primary lift">
              Code
            </a>

          </div>
        </div> <!-- / .row -->
      </div> <!-- / .container -->
    </section>

    <!-- FOOTER -->
    {{> partials/footer classList="bg-white"}}

    <!-- JAVASCRIPT -->
    {{> partials/scripts}}

  </body>
</html>
